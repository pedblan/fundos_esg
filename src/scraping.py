# -*- coding: utf-8 -*-"""Baixa regulamentos dos fundos ASG listados no site da Anbima e coleta dados das respectivas páginas."""import jsonfrom selenium import webdriverfrom selenium.webdriver.common.by import Byimport requestsimport time, randomfrom datetime import dateimport reimport osdriver = webdriver.Chrome() driver.implicitly_wait(10)def buscar_links(url):    """Faz o scraping dos links contidos em apenas uma página de resultados de pesquisa no site da Anbima. Procedimento deve ser repetido para cada uma das páginas de resultados."""    links = []    driver.get(url)    metadados = []    numero_de_registros = len(driver.find_elements(By.CLASS_NAME, "list-item__title"))    for i in range(numero_de_registros):        try:            elemento = driver.find_element(By.ID, f'item-title-{i}')            links.append(elemento.get_attribute('href'))        except Exception as e:            print(f"Erro ao tentar encontrar o elemento com ID item-title-{i}: {e}")    return linksdef scraping_metadados(link):    """Acessa e faz scraping da página para coletar metadados. Retorna False, caso o fundo tenha sido encerrado."""    time.sleep(1 + random.random())    driver.get(link)    time.sleep(5 + random.random())    fields = driver.find_elements(By.CLASS_NAME, 'anbima-ui-output__label')    values = driver.find_elements(By.CLASS_NAME, 'anbima-ui-output__value')    data = {field.text: value.text for field, value in zip(fields, values)}    if driver.find_element(By.XPATH,                                                                                 '//*[@id="situacaoAtualFundo"]/label').text == 'ENCERRADO':        return False    data[f"Status em {date.today().strftime('%d/%m/%Y')}"] = driver.find_element(By.XPATH,                                                                                 '//*[@id="situacaoAtualFundo"]/label').text    data["URL do Fundo"] = driver.current_url    data["Fundo"] = driver.find_element(By.XPATH, '//*[@id="root"]/main/div[2]/div/div[2]/div/h1').text    data["Arquivo"] = data["Fundo"].replace('/', '-').replace('\\', '-')    return datadef download_regulamento(arquivo, diretorio):    """Faz o download do regulamento se ele ainda não existe e é um PDF."""    try:        download_button = driver.find_element(By.XPATH, '//*[@id="output__container--"]/div/span/button/span')        download_button.click()        time.sleep(4 + random.random())        if len(driver.window_handles) > 1:            driver.switch_to.window(driver.window_handles[1])            file_url = driver.current_url            driver.close()            driver.switch_to.window(driver.window_handles[0])        else:            file_url = driver.current_url        file_path = os.path.join(diretorio, f'{arquivo}.pdf')        if not os.path.exists(file_path):            response = requests.get(file_url)            content_type = response.headers['Content-Type']            if 'application/pdf' in content_type:                with open(file_path, 'wb') as file:                    file.write(response.content)                print(f'Regulamento {arquivo} descarregado.')                return file_path            else:                print(f"O arquivo para {arquivo} não é um PDF.")                return None        else:            print(f'O regulamento {arquivo} já existe no diretório.')            return file_path    except Exception as e:        print(f"Erro ao tentar descarregar o regulamento para {arquivo}: {e}")        return None        def problema_1(metadados):    """Corrige a inclusão do botão 'baixar' na tabela de informações coletadas pelo scraping da página de fundo."""    for dicionario in metadados:        for chave, valor in dicionario.items():            if valor == 'Baixar':                if chave == 'Saldo mínimo aplicado':                    dicionario[chave] = "n/d"                elif chave == 'Regulamento\nData de atualização indisponível':                    dicionario[chave] = "n/d"            elif valor == '':                dicionario[chave] = "n/d"            elif valor == '-':                dicionario[chave] = "n/d"            def problema_2(metadados):    """Corrige o problema de formatação relacionado à data de atualização da página do fundo na tabela de dados coletados pelo scraping."""    regex_data = r'\d{2}/\d{2}/\d{4}'    for dicionario in metadados:        for chave in list(dicionario.keys()):            if "Regulamento" in chave:                match = re.search(regex_data, chave)                novo_valor = match.group() if match else "n/d"                dicionario['Última atualização'] = novo_valor                del dicionario[chave]def problema_3(metadados):    """Corrige a inclusão de campo em branco na tabela de dados coletados pelo scraping."""    for dicionario in metadados:    # Iterar por uma cópia do dicionário para evitar RuntimeError ao modificar o tamanho durante a iteração        for chave in list(dicionario.keys()):            if chave == '':                del dicionario[chave]def problema_4(metadados):    """Separa o valor da cota e o da rentabilidade em células diferentes da tabela de dados coletados."""    # Expressão regular para extrair o valor da cota e a rentabilidade    regex = r'R\$ ([\d,\.]+)(?: ([+-]?\d{1,2},\d{2}%))?'        for dicionario in metadados:        valor_original = dicionario.get('Valor da cota / Rentabilidade 12 meses', '')        match = re.match(regex, valor_original.replace('.', ','))                if match:            valor_da_cota = match.group(1).replace(',', '.')            rentabilidade = match.group(2) if match.group(2) else "n/d"                        # Atualizar o dicionário com novas chaves            dicionario['Valor da cota'] = valor_da_cota            dicionario['Rentabilidade 12 meses'] = rentabilidade                # Remover a chave original, se necessário            del dicionario['Valor da cota / Rentabilidade 12 meses']